{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting video processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing clips: 100%|██████████| 84/84 [04:15<00:00,  3.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Statistics:\n",
      "Total clips: 144\n",
      "\n",
      "Clips per class:\n",
      "Class 0: 78 clips\n",
      "Class 1: 36 clips\n",
      "Class 2: 30 clips\n",
      "\n",
      "Processing complete!\n",
      "Successfully created 144 clips\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_video_dataset(\n",
    "    video_path: str,\n",
    "    labels_csv_path: str,\n",
    "    output_base_dir: str,\n",
    "    clip_duration: int = 10,\n",
    "    total_clips: int = 84,\n",
    "    fps: int = 30\n",
    "):\n",
    "    \"\"\"\n",
    "    Process a long video file into clips without audio and organize them by class labels.\n",
    "    \n",
    "    Args:\n",
    "        video_path: Path to the source MKV video file\n",
    "        labels_csv_path: Path to CSV file containing labels\n",
    "        output_base_dir: Base directory for output class folders\n",
    "        clip_duration: Duration of each clip in seconds\n",
    "        total_clips: Total number of clips to generate\n",
    "        fps: Frames per second to maintain in output\n",
    "    \"\"\"\n",
    "    # Create output directory\n",
    "    Path(output_base_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Read labels\n",
    "    labels_df = pd.read_csv(labels_csv_path)\n",
    "    \n",
    "    # Open video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Get video properties\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    video_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # Calculate middle 14 minutes in frames\n",
    "    total_duration = total_frames / video_fps\n",
    "    start_time = (total_duration - (14 * 60)) / 2\n",
    "    start_frame = int(start_time * video_fps)\n",
    "    \n",
    "    # Create class directories\n",
    "    unique_labels = sorted(labels_df['cs'].unique())  # Using 'cs' column\n",
    "    class_dirs = {}\n",
    "    for label in unique_labels:\n",
    "        class_dir = os.path.join(output_base_dir, str(label))\n",
    "        Path(class_dir).mkdir(parents=True, exist_ok=True)\n",
    "        class_dirs[label] = class_dir\n",
    "    \n",
    "    # Calculate frames per clip\n",
    "    frames_per_clip = int(clip_duration * fps)\n",
    "    \n",
    "    print(\"Starting video processing...\")\n",
    "    \n",
    "    # Process each clip\n",
    "    for clip_idx in tqdm(range(total_clips), desc=\"Processing clips\"):\n",
    "        # Calculate frame ranges for this clip\n",
    "        clip_start_frame = start_frame + (clip_idx * frames_per_clip)\n",
    "        clip_end_frame = clip_start_frame + frames_per_clip\n",
    "        \n",
    "        # Get label for this clip (using mode of 10 seconds worth of labels)\n",
    "        label_start_idx = clip_idx * 10\n",
    "        label_end_idx = label_start_idx + 10\n",
    "        clip_label = labels_df.iloc[label_start_idx:label_end_idx]['cs'].mode().iloc[0]\n",
    "        \n",
    "        # Setup output video writer\n",
    "        clip_name = f'clip_{clip_idx:03d}.mp4'\n",
    "        clip_path = os.path.join(class_dirs[clip_label], clip_name)\n",
    "        \n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(clip_path, fourcc, fps, (frame_width, frame_height))\n",
    "        \n",
    "        # Set frame position\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, clip_start_frame)\n",
    "        \n",
    "        # Read and write frames for this clip\n",
    "        frames_written = 0\n",
    "        while frames_written < frames_per_clip:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            out.write(frame)\n",
    "            frames_written += 1\n",
    "        \n",
    "        # Release video writer\n",
    "        out.release()\n",
    "        \n",
    "        # Verify clip was created successfully\n",
    "        if not os.path.exists(clip_path) or os.path.getsize(clip_path) == 0:\n",
    "            print(f\"Warning: Failed to create clip {clip_idx}\")\n",
    "            continue\n",
    "    \n",
    "    # Clean up\n",
    "    cap.release()\n",
    "    \n",
    "    return verify_dataset(output_base_dir)\n",
    "\n",
    "def verify_dataset(output_base_dir: str):\n",
    "    \"\"\"\n",
    "    Verify the processed dataset and return statistics.\n",
    "    \n",
    "    Args:\n",
    "        output_base_dir: Base directory containing class folders\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dataset statistics\n",
    "    \"\"\"\n",
    "    stats = {\n",
    "        'total_clips': 0,\n",
    "        'class_distribution': {},\n",
    "        'problematic_clips': []\n",
    "    }\n",
    "    \n",
    "    # Check each class directory\n",
    "    for class_dir in Path(output_base_dir).iterdir():\n",
    "        if class_dir.is_dir():\n",
    "            class_name = class_dir.name\n",
    "            clips = list(class_dir.glob('*.mp4'))\n",
    "            stats['class_distribution'][class_name] = len(clips)\n",
    "            stats['total_clips'] += len(clips)\n",
    "            \n",
    "            # Check each clip\n",
    "            for clip_path in clips:\n",
    "                cap = cv2.VideoCapture(str(clip_path))\n",
    "                if not cap.isOpened():\n",
    "                    stats['problematic_clips'].append(str(clip_path))\n",
    "                else:\n",
    "                    # Verify frame count\n",
    "                    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                    if frame_count == 0:\n",
    "                        stats['problematic_clips'].append(str(clip_path))\n",
    "                cap.release()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(\"\\nDataset Statistics:\")\n",
    "    print(f\"Total clips: {stats['total_clips']}\")\n",
    "    print(\"\\nClips per class:\")\n",
    "    for class_name, count in sorted(stats['class_distribution'].items()):\n",
    "        print(f\"Class {class_name}: {count} clips\")\n",
    "    \n",
    "    if stats['problematic_clips']:\n",
    "        print(\"\\nWarning: The following clips may be corrupted:\")\n",
    "        for clip in stats['problematic_clips']:\n",
    "            print(f\"- {clip}\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the video preprocessing pipeline.\n",
    "    \"\"\"\n",
    "    # Configuration\n",
    "    config = {\n",
    "        'video_path': \"13_video.mkv\",\n",
    "        'labels_csv_path': \"cs_labels30.csv\",\n",
    "        'output_base_dir': \"vrwalking\",\n",
    "        'clip_duration': 10,  # seconds\n",
    "        'total_clips': 84,\n",
    "        'fps': 60\n",
    "    }\n",
    "    \n",
    "    # Process dataset\n",
    "    stats = process_video_dataset(**config)\n",
    "    \n",
    "    # Print final status\n",
    "    print(\"\\nProcessing complete!\")\n",
    "    print(f\"Successfully created {stats['total_clips']} clips\")\n",
    "    if stats['problematic_clips']:\n",
    "        print(f\"Found {len(stats['problematic_clips'])} problematic clips\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting moviepy\n",
      "  Downloading moviepy-1.0.3.tar.gz (388 kB)\n",
      "     ---------------------------------------- 0.0/388.3 kB ? eta -:--:--\n",
      "     -- ---------------------------------- 30.7/388.3 kB 660.6 kB/s eta 0:00:01\n",
      "     ----------------- -------------------- 174.1/388.3 kB 2.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- 388.3/388.3 kB 3.5 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting decorator<5.0,>=4.0.2 (from moviepy)\n",
      "  Downloading decorator-4.4.2-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in c:\\users\\jyoti\\anaconda3\\envs\\save\\lib\\site-packages (from moviepy) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in c:\\users\\jyoti\\anaconda3\\envs\\save\\lib\\site-packages (from moviepy) (2.31.0)\n",
      "Collecting proglog<=1.0.0 (from moviepy)\n",
      "  Downloading proglog-0.1.10-py3-none-any.whl.metadata (639 bytes)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\jyoti\\anaconda3\\envs\\save\\lib\\site-packages (from moviepy) (1.26.2)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in c:\\users\\jyoti\\anaconda3\\envs\\save\\lib\\site-packages (from moviepy) (2.35.0)\n",
      "Collecting imageio_ffmpeg>=0.2.0 (from moviepy)\n",
      "  Downloading imageio_ffmpeg-0.5.1-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\jyoti\\anaconda3\\envs\\save\\lib\\site-packages (from imageio<3.0,>=2.5->moviepy) (10.1.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jyoti\\anaconda3\\envs\\save\\lib\\site-packages (from imageio_ffmpeg>=0.2.0->moviepy) (68.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jyoti\\anaconda3\\envs\\save\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jyoti\\anaconda3\\envs\\save\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jyoti\\anaconda3\\envs\\save\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jyoti\\anaconda3\\envs\\save\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2023.11.17)\n",
      "Requirement already satisfied: colorama in c:\\users\\jyoti\\anaconda3\\envs\\save\\lib\\site-packages (from tqdm<5.0,>=4.11.2->moviepy) (0.4.6)\n",
      "Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Downloading imageio_ffmpeg-0.5.1-py3-none-win_amd64.whl (22.6 MB)\n",
      "   ---------------------------------------- 0.0/22.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/22.6 MB 10.5 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 1.1/22.6 MB 11.2 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 1.6/22.6 MB 11.4 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.8/22.6 MB 11.7 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 2.0/22.6 MB 8.6 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 2.5/22.6 MB 9.4 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.1/22.6 MB 9.7 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 3.6/22.6 MB 10.0 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 4.2/22.6 MB 10.2 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 4.7/22.6 MB 10.4 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 5.3/22.6 MB 10.5 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 5.8/22.6 MB 10.6 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 6.4/22.6 MB 10.7 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 6.9/22.6 MB 10.8 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 7.5/22.6 MB 10.8 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 8.0/22.6 MB 10.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 8.6/22.6 MB 10.9 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 9.1/22.6 MB 10.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 9.6/22.6 MB 11.0 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 10.2/22.6 MB 11.0 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 10.7/22.6 MB 11.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 11.3/22.6 MB 11.1 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 11.8/22.6 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 12.4/22.6 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 12.9/22.6 MB 11.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 13.4/22.6 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 13.9/22.6 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 13.9/22.6 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 13.9/22.6 MB 11.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 15.2/22.6 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 15.7/22.6 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 16.3/22.6 MB 11.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 16.8/22.6 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 17.4/22.6 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 17.9/22.6 MB 11.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 18.5/22.6 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 19.0/22.6 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 19.6/22.6 MB 11.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 20.2/22.6 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 20.7/22.6 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 21.2/22.6 MB 11.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 21.8/22.6 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  22.3/22.6 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  22.6/22.6 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  22.6/22.6 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  22.6/22.6 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 22.6/22.6 MB 9.9 MB/s eta 0:00:00\n",
      "Downloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\n",
      "Building wheels for collected packages: moviepy\n",
      "  Building wheel for moviepy (setup.py): started\n",
      "  Building wheel for moviepy (setup.py): finished with status 'done'\n",
      "  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110765 sha256=2be36fbb58d35a0aed26e1acd9138ee2c840bc6e5d188a4fa729d200ca318761\n",
      "  Stored in directory: c:\\users\\jyoti\\appdata\\local\\pip\\cache\\wheels\\83\\b1\\d9\\119ef7c144b44d591ec0a9a140465133c23ea95d2a161184ba\n",
      "Successfully built moviepy\n",
      "Installing collected packages: imageio_ffmpeg, decorator, proglog, moviepy\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 5.1.1\n",
      "    Uninstalling decorator-5.1.1:\n",
      "      Successfully uninstalled decorator-5.1.1\n",
      "Successfully installed decorator-4.4.2 imageio_ffmpeg-0.5.1 moviepy-1.0.3 proglog-0.1.10\n"
     ]
    }
   ],
   "source": [
    "!pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution Statistics:\n",
      "33rd percentile (Class 0-1 boundary): 1.00\n",
      "66th percentile (Class 1-2 boundary): 2.00\n",
      "\n",
      "Class Definitions:\n",
      "Class 0 (Low): FMS ≤ 1.00\n",
      "Class 1 (Moderate): 1.00 < FMS ≤ 2.00\n",
      "Class 2 (High): FMS > 2.00\n",
      "\n",
      "Detailed Statistics by Class:\n",
      "\n",
      "Class 0:\n",
      "  Count: 16800\n",
      "  Mean FMS: 1.00\n",
      "  Min FMS: 1.00\n",
      "  Max FMS: 1.00\n",
      "\n",
      "Class 1:\n",
      "  Count: 3240\n",
      "  Mean FMS: 2.00\n",
      "  Min FMS: 2.00\n",
      "  Max FMS: 2.00\n",
      "\n",
      "Class 2:\n",
      "  Count: 6840\n",
      "  Mean FMS: 4.31\n",
      "  Min FMS: 3.00\n",
      "  Max FMS: 7.00\n",
      "\n",
      "Overall Class Distribution:\n",
      "cs\n",
      "0    16800\n",
      "1     3240\n",
      "2     6840\n",
      "\n",
      "Processed CSV saved to: cs_labels.csv\n",
      "\n",
      "Summary statistics saved to: cs_labels_summary.csv\n",
      "\n",
      "Sample of processed data:\n",
      "   fms  cs\n",
      "0    1   0\n",
      "1    1   0\n",
      "2    1   0\n",
      "3    1   0\n",
      "4    1   0\n",
      "5    1   0\n",
      "6    1   0\n",
      "7    1   0\n",
      "8    1   0\n",
      "9    1   0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def create_cybersickness_classes(csv_path, output_path=None):\n",
    "    \"\"\"\n",
    "    Read FMS data and create 3 cybersickness severity classes based on distribution.\n",
    "    \n",
    "    Args:\n",
    "        csv_path: Path to input CSV file with FMS column\n",
    "        output_path: Path to save the modified CSV file (if None, will add '_processed' to input filename)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with new 'cs' column\n",
    "    \"\"\"\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Ensure FMS column exists\n",
    "    if 'fms' not in df.columns:\n",
    "        raise ValueError(\"Column 'fms' not found in CSV file\")\n",
    "    \n",
    "    # Calculate distribution statistics using 33rd and 66th percentiles\n",
    "    p33, p66 = np.percentile(df['fms'], [33.33, 66.67])\n",
    "    \n",
    "    # Create cybersickness severity classes\n",
    "    def assign_class(fms):\n",
    "        if fms <= p33:\n",
    "            return 0    # Low\n",
    "        elif fms <= p66:\n",
    "            return 1    # Moderate\n",
    "        else:\n",
    "            return 2    # High\n",
    "    \n",
    "    # Add new column for cybersickness class\n",
    "    df['cs'] = df['fms'].apply(assign_class)\n",
    "    \n",
    "    # Generate distribution analysis\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot 1: FMS Distribution\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(data=df, x='fms', bins=10)\n",
    "    plt.axvline(p33, color='r', linestyle='--', label=f'33rd percentile ({p33:.2f})')\n",
    "    plt.axvline(p66, color='g', linestyle='--', label=f'66th percentile ({p66:.2f})')\n",
    "    plt.title('FMS Score Distribution')\n",
    "    plt.xlabel('FMS Score')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot 2: Class Distribution\n",
    "    plt.subplot(1, 2, 2)\n",
    "    class_counts = df['cs'].value_counts().sort_index()\n",
    "    sns.barplot(x=class_counts.index, y=class_counts.values)\n",
    "    plt.title('Cybersickness Class Distribution')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Count')\n",
    "    \n",
    "    # Add class labels\n",
    "    for i, count in enumerate(class_counts):\n",
    "        plt.text(i, count, str(count), ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the visualization\n",
    "    plt.savefig('cybersickness_distribution.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Print distribution statistics\n",
    "    print(\"\\nDistribution Statistics:\")\n",
    "    print(f\"33rd percentile (Class 0-1 boundary): {p33:.2f}\")\n",
    "    print(f\"66th percentile (Class 1-2 boundary): {p66:.2f}\")\n",
    "    \n",
    "    print(\"\\nClass Definitions:\")\n",
    "    print(f\"Class 0 (Low): FMS ≤ {p33:.2f}\")\n",
    "    print(f\"Class 1 (Moderate): {p33:.2f} < FMS ≤ {p66:.2f}\")\n",
    "    print(f\"Class 2 (High): FMS > {p66:.2f}\")\n",
    "    \n",
    "    # Additional statistics\n",
    "    print(\"\\nDetailed Statistics by Class:\")\n",
    "    for class_num in range(3):\n",
    "        class_data = df[df['cs'] == class_num]['fms']\n",
    "        print(f\"\\nClass {class_num}:\")\n",
    "        print(f\"  Count: {len(class_data)}\")\n",
    "        print(f\"  Mean FMS: {class_data.mean():.2f}\")\n",
    "        print(f\"  Min FMS: {class_data.min():.2f}\")\n",
    "        print(f\"  Max FMS: {class_data.max():.2f}\")\n",
    "    \n",
    "    print(\"\\nOverall Class Distribution:\")\n",
    "    print(df['cs'].value_counts().sort_index().to_string())\n",
    "    \n",
    "    # Save the modified DataFrame\n",
    "    if output_path is None:\n",
    "        output_path = csv_path.rsplit('.', 1)[0] + '_processed.csv'\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"\\nProcessed CSV saved to: {output_path}\")\n",
    "    \n",
    "    # Create a summary DataFrame\n",
    "    summary_df = pd.DataFrame({\n",
    "        'Class': ['Low (0)', 'Moderate (1)', 'High (2)'],\n",
    "        'FMS_Range': [\n",
    "            f'≤ {p33:.2f}',\n",
    "            f'{p33:.2f} - {p66:.2f}',\n",
    "            f'> {p66:.2f}'\n",
    "        ],\n",
    "        'Count': [\n",
    "            len(df[df['cs'] == 0]),\n",
    "            len(df[df['cs'] == 1]),\n",
    "            len(df[df['cs'] == 2])\n",
    "        ],\n",
    "        'Percentage': [\n",
    "            f\"{(len(df[df['cs'] == 0])/len(df)*100):.1f}%\",\n",
    "            f\"{(len(df[df['cs'] == 1])/len(df)*100):.1f}%\",\n",
    "            f\"{(len(df[df['cs'] == 2])/len(df)*100):.1f}%\"\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Save summary to CSV\n",
    "    summary_path = output_path.rsplit('.', 1)[0] + '_summary.csv'\n",
    "    summary_df.to_csv(summary_path, index=False)\n",
    "    print(f\"\\nSummary statistics saved to: {summary_path}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    # Configuration\n",
    "    INPUT_CSV_PATH = \"Cybersickness_Label.csv\"\n",
    "    OUTPUT_CSV_PATH = \"cs_labels.csv\"  # Optional\n",
    "    \n",
    "    # Process the data\n",
    "    df = create_cybersickness_classes(INPUT_CSV_PATH, OUTPUT_CSV_PATH)\n",
    "    \n",
    "    # Display sample of the processed data\n",
    "    print(\"\\nSample of processed data:\")\n",
    "    print(df[['fms', 'cs']].head(10))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "save",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
